{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPG4eBY+TK3yPMkSzulfjkC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e918cbc91e774c26b679a4a5001620ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61297b4a6f6144fab26019652ea4272e","IPY_MODEL_85286d9540934d4491ad591a9f57aa0c","IPY_MODEL_fc3f0ed9fcfd4798957775bdf6e2e75a"],"layout":"IPY_MODEL_5dcd042a8648457e83a7a89e10b5b8ac"}},"61297b4a6f6144fab26019652ea4272e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53b6137fae40413a91a3c42f90ae50bc","placeholder":"‚Äã","style":"IPY_MODEL_a4c6a36a082243148f18ce220d942511","value":"Loading‚Äáweights:‚Äá100%"}},"85286d9540934d4491ad591a9f57aa0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09479acc603f402891738b994eb33247","max":199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc833aafcade4e5da9cca2ccf7d2160a","value":199}},"fc3f0ed9fcfd4798957775bdf6e2e75a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c238c3215a28403d89eb45d6d3faf187","placeholder":"‚Äã","style":"IPY_MODEL_619baab3f3b64dd99afd7d132f71bb00","value":"‚Äá199/199‚Äá[00:00&lt;00:00,‚Äá426.56it/s,‚ÄáMaterializing‚Äáparam=pooler.dense.weight]"}},"5dcd042a8648457e83a7a89e10b5b8ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53b6137fae40413a91a3c42f90ae50bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4c6a36a082243148f18ce220d942511":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09479acc603f402891738b994eb33247":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc833aafcade4e5da9cca2ccf7d2160a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c238c3215a28403d89eb45d6d3faf187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"619baab3f3b64dd99afd7d132f71bb00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4782799ddca4d979db10f5070afb3f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c97fb65c833b4aa08018660c860951dd","IPY_MODEL_5f67ae50563c442fb05f701ba8455bca","IPY_MODEL_c93d493df4e440b4b0a34738894d1f37"],"layout":"IPY_MODEL_67705a166d7244cbbd69a3ab4a377e94"}},"c97fb65c833b4aa08018660c860951dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aaafb58cae94ab6bde8a7379174aeee","placeholder":"‚Äã","style":"IPY_MODEL_e4bfa8279c0d4e4082f959e7e383efee","value":"Batches:‚Äá100%"}},"5f67ae50563c442fb05f701ba8455bca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c808335510c4cbe8399d10c3f512c04","max":1028,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da444488397e413ba18ccb4249826c02","value":1028}},"c93d493df4e440b4b0a34738894d1f37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97918102d4d047ce96f7103c6f9d2a63","placeholder":"‚Äã","style":"IPY_MODEL_aa28ef3c6d4347b9818399624ffb85b8","value":"‚Äá1028/1028‚Äá[07:09&lt;00:00,‚Äá91.35it/s]"}},"67705a166d7244cbbd69a3ab4a377e94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aaafb58cae94ab6bde8a7379174aeee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4bfa8279c0d4e4082f959e7e383efee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c808335510c4cbe8399d10c3f512c04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da444488397e413ba18ccb4249826c02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97918102d4d047ce96f7103c6f9d2a63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa28ef3c6d4347b9818399624ffb85b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e918cbc91e774c26b679a4a5001620ef","61297b4a6f6144fab26019652ea4272e","85286d9540934d4491ad591a9f57aa0c","fc3f0ed9fcfd4798957775bdf6e2e75a","5dcd042a8648457e83a7a89e10b5b8ac","53b6137fae40413a91a3c42f90ae50bc","a4c6a36a082243148f18ce220d942511","09479acc603f402891738b994eb33247","bc833aafcade4e5da9cca2ccf7d2160a","c238c3215a28403d89eb45d6d3faf187","619baab3f3b64dd99afd7d132f71bb00","a4782799ddca4d979db10f5070afb3f2","c97fb65c833b4aa08018660c860951dd","5f67ae50563c442fb05f701ba8455bca","c93d493df4e440b4b0a34738894d1f37","67705a166d7244cbbd69a3ab4a377e94","8aaafb58cae94ab6bde8a7379174aeee","e4bfa8279c0d4e4082f959e7e383efee","3c808335510c4cbe8399d10c3f512c04","da444488397e413ba18ccb4249826c02","97918102d4d047ce96f7103c6f9d2a63","aa28ef3c6d4347b9818399624ffb85b8"]},"id":"fx5h7iXhDFl5","executionInfo":{"status":"ok","timestamp":1770121649502,"user_tz":-60,"elapsed":523152,"user":{"displayName":"Vishnu","userId":"12017236183701689595"}},"outputId":"ee1a5a6e-d65b-4ae7-fc1d-8d25916adb93"},"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","ICECAT TAXONOMY CLUSTERING - COMPLETE PIPELINE\n","Target: 90%+ Accuracy\n","================================================================================\n","\n","[1/10] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","[2/10] Installing dependencies (this may take a few minutes)...\n","\n","\n","[3/10] Loading libraries...\n","All libraries loaded!\n","\n","[4/10] Setting up configuration...\n","‚úÖ Configuration set\n","   Data path: /content/drive/MyDrive/Colab Notebooks/Case_Studies_Taxonomy/data/icecat_data_train.json\n","   Target accuracy: 90%\n","   Target purity: 90%\n","\n","================================================================================\n","DATA LOADING & PREPROCESSING\n","================================================================================\n","\n","[5/10] Loading dataset...\n","‚úÖ Loaded 489,902 products with 45 fields\n","\n","   Parsing hierarchy (pathlist_names)...\n","   Original products: 489,902\n","   After filtering ‚â•3 levels: 489,902\n","   Unique level3 categories: 231\n","\n","   Filtering categories (‚â•200 products)...\n","   After filtering: 481,893 products, 114 categories\n","\n","   Balancing dataset (300 products per category)...\n","   Balanced dataset: 32,885 products, 114 categories\n","   Products per category: ~288\n","\n","‚úÖ Preprocessing complete!\n","\n","================================================================================\n","TEXT FEATURE ENGINEERING\n","================================================================================\n","\n","[6/10] Creating combined text features...\n","‚úÖ Combined text created\n","   Average length: 951 characters\n","\n","================================================================================\n","EMBEDDING GENERATION\n","================================================================================\n","\n","[7/10] Generating embeddings with sentence-transformers/all-mpnet-base-v2...\n","   (This may take 5-10 minutes depending on dataset size)\n"]},{"output_type":"display_data","data":{"text/plain":["Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e918cbc91e774c26b679a4a5001620ef"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n","Key                     | Status     |  | \n","------------------------+------------+--+-\n","embeddings.position_ids | UNEXPECTED |  | \n","\n","Notes:\n","- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"]},{"output_type":"stream","name":"stdout","text":["   Model loaded: 768-dimensional embeddings\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/1028 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4782799ddca4d979db10f5070afb3f2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Embeddings generated: (32885, 768)\n"]}],"source":["#This is the Colab Script for the production-level implementation of Taxonomy Case Study\n","\n","# =============================================================================\n","# PART 1: SETUP & IMPORTS\n","# =============================================================================\n","\n","print(\"=\"*80)\n","print(\"ICECAT TAXONOMY CLUSTERING - COMPLETE PIPELINE\")\n","print(\"Target: 90%+ Accuracy\")\n","print(\"=\"*80)\n","\n","# Mount Google Drive\n","print(\"\\n[1/10] Mounting Google Drive...\")\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Install dependencies\n","print(\"\\n[2/10] Installing dependencies (this may take a few minutes)...\\n\")\n","!pip install -q sentence-transformers umap-learn hdbscan matplotlib seaborn scikit-learn pandas numpy tqdm\n","\n","# Imports\n","print(\"\\n[3/10] Loading libraries...\")\n","import json\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm.auto import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# ML libraries\n","from sentence_transformers import SentenceTransformer\n","from sklearn.cluster import DBSCAN, Birch, AgglomerativeClustering\n","from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, silhouette_score\n","import hdbscan\n","import umap\n","\n","print(\"All libraries loaded!\")\n","\n","# =============================================================================\n","# PART 2: CONFIGURATION\n","# =============================================================================\n","\n","print(\"\\n[4/10] Setting up configuration...\")\n","\n","\n","DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/Case_Studies_Taxonomy/data/icecat_data_train.json'\n","OUTPUT_DIR = '/content/drive/MyDrive/Colab Notebooks/Case_Studies_Taxonomy/outputs'\n","\n","# Data preprocessing (from corrections_2.txt)\n","MIN_HIERARCHY_LEVELS = 3\n","MIN_PRODUCTS_PER_CATEGORY = 200\n","BALANCE_SAMPLE_SIZE = 300\n","\n","# Embeddings\n","EMBEDDING_MODEL = 'sentence-transformers/all-mpnet-base-v2'\n","EMBEDDING_BATCH_SIZE = 32\n","\n","# Targets (from corrections_3.txt)\n","TARGET_PURITY = 0.90\n","TARGET_ACCURACY = 0.90\n","\n","# Visualization\n","VIZ_SAMPLE_SIZE = 10000\n","RANDOM_SEED = 42\n","\n","print(f\"‚úÖ Configuration set\")\n","print(f\"   Data path: {DATA_PATH}\")\n","print(f\"   Target accuracy: {TARGET_ACCURACY:.0%}\")\n","print(f\"   Target purity: {TARGET_PURITY:.0%}\")\n","\n","# Create output directory\n","import os\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# =============================================================================\n","# PART 3: DATA LOADING & PREPROCESSING\n","# =============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"DATA LOADING & PREPROCESSING\")\n","print(\"=\"*80)\n","\n","print(\"\\n[5/10] Loading dataset...\")\n","\n","# Load column-oriented JSON\n","with open(DATA_PATH, 'r', encoding='utf-8') as f:\n","    column_data = json.load(f)\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(column_data)\n","print(f\"‚úÖ Loaded {len(df):,} products with {len(df.columns)} fields\")\n","\n","# Parse hierarchy\n","print(\"\\n   Parsing hierarchy (pathlist_names)...\")\n","df['hierarchy_levels'] = df['pathlist_names'].str.split('>')\n","df['num_levels'] = df['hierarchy_levels'].str.len()\n","\n","print(f\"   Original products: {len(df):,}\")\n","\n","# Remove products with < 3 levels (NO PADDING as per corrections_2.txt)\n","df = df[df['num_levels'] >= MIN_HIERARCHY_LEVELS].copy()\n","print(f\"   After filtering ‚â•3 levels: {len(df):,}\")\n","\n","# Extract level1, level2, level3\n","df['level1'] = df['hierarchy_levels'].str[0].str.strip()\n","df['level2'] = df['hierarchy_levels'].str[1].str.strip()\n","df['level3'] = df['hierarchy_levels'].str[2].str.strip()\n","\n","print(f\"   Unique level3 categories: {df['level3'].nunique()}\")\n","\n","# Filter categories (keep only ‚â• MIN_PRODUCTS_PER_CATEGORY)\n","print(f\"\\n   Filtering categories (‚â•{MIN_PRODUCTS_PER_CATEGORY} products)...\")\n","category_counts = df['level3'].value_counts()\n","valid_categories = category_counts[category_counts >= MIN_PRODUCTS_PER_CATEGORY].index\n","df = df[df['level3'].isin(valid_categories)].copy()\n","\n","print(f\"   After filtering: {len(df):,} products, {df['level3'].nunique()} categories\")\n","\n","# Balance dataset (sample N products per category)\n","print(f\"\\n   Balancing dataset ({BALANCE_SAMPLE_SIZE} products per category)...\")\n","\n","balanced_dfs = []\n","for category in df['level3'].unique():\n","    category_df = df[df['level3'] == category]\n","    n_samples = min(len(category_df), BALANCE_SAMPLE_SIZE)\n","    replace = len(category_df) < BALANCE_SAMPLE_SIZE\n","    sampled = category_df.sample(n=n_samples, replace=replace, random_state=RANDOM_SEED)\n","    balanced_dfs.append(sampled)\n","\n","df = pd.concat(balanced_dfs, ignore_index=True)\n","df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n","\n","print(f\"   Balanced dataset: {len(df):,} products, {df['level3'].nunique()} categories\")\n","print(f\"   Products per category: ~{len(df) // df['level3'].nunique()}\")\n","\n","# Drop temporary columns\n","df = df.drop(columns=['hierarchy_levels', 'num_levels'], errors='ignore')\n","\n","print(\"\\n‚úÖ Preprocessing complete!\")\n","\n","# =============================================================================\n","# PART 4: TEXT FEATURE ENGINEERING\n","# =============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"TEXT FEATURE ENGINEERING\")\n","print(\"=\"*80)\n","\n","print(\"\\n[6/10] Creating combined text features...\")\n","\n","# Concatenate LongProductName + LongDesc (from corrections_2.txt)\n","text_parts = []\n","\n","if 'Description.LongProductName' in df.columns:\n","    text_parts.append(df['Description.LongProductName'].fillna('').astype(str))\n","if 'Description.LongDesc' in df.columns:\n","    text_parts.append(df['Description.LongDesc'].fillna('').astype(str))\n","\n","if not text_parts:\n","    raise ValueError(\"No text fields found!\")\n","\n","df['combined_text'] = text_parts[0]\n","for part in text_parts[1:]:\n","    df['combined_text'] = df['combined_text'] + ' | ' + part\n","\n","df['combined_text'] = df['combined_text'].str.strip()\n","\n","avg_len = df['combined_text'].str.len().mean()\n","print(f\"‚úÖ Combined text created\")\n","print(f\"   Average length: {avg_len:.0f} characters\")\n","\n","# =============================================================================\n","# PART 5: EMBEDDING GENERATION\n","# =============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"EMBEDDING GENERATION\")\n","print(\"=\"*80)\n","\n","print(f\"\\n[7/10] Generating embeddings with {EMBEDDING_MODEL}...\")\n","print(\"   (This may take 5-10 minutes depending on dataset size)\")\n","\n","# Load model\n","model = SentenceTransformer(EMBEDDING_MODEL)\n","print(f\"   Model loaded: {model.get_sentence_embedding_dimension()}-dimensional embeddings\")\n","\n","# Generate embeddings\n","texts = df['combined_text'].tolist()\n","embeddings = model.encode(\n","    texts,\n","    batch_size=EMBEDDING_BATCH_SIZE,\n","    show_progress_bar=True,\n","    convert_to_numpy=True\n",")\n","\n","print(f\"‚úÖ Embeddings generated: {embeddings.shape}\")\n","\n"]},{"cell_type":"code","source":["# =============================================================================\n","# PART 6: CLUSTERING (OPTIMIZED FOR SPEED)\n","# =============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"CLUSTERING ALGORITHMS (OPTIMIZED FOR ACCURACY)\")\n","print(\"=\"*80)\n","\n","true_labels = df['level3'].values\n","n_true_categories = len(set(true_labels))\n","\n","print(f\"   True categories: {n_true_categories}\")\n","print(f\"   Total products: {len(embeddings):,}\")\n","\n","clustering_results = {}\n","\n","# --------------------------------------------------\n","# Algorithm 1: HDBSCAN (OPTIMIZED)\n","# --------------------------------------------------\n","print(\"\\n   [Algorithm 1/4] HDBSCAN (optimized)...\")\n","import time\n","start = time.time()\n","\n","hdbscan_clusterer = hdbscan.HDBSCAN(\n","    min_cluster_size=max(30, len(embeddings) // (n_true_categories * 3)),  # Dynamic\n","    min_samples=3,\n","    metric='euclidean',\n","    cluster_selection_epsilon=0.0,  # No merging\n","    cluster_selection_method='leaf',  # More granular clusters\n","    core_dist_n_jobs=-1\n",")\n","labels_hdbscan = hdbscan_clusterer.fit_predict(embeddings)\n","n_clusters_hdbscan = len(set(labels_hdbscan)) - (1 if -1 in labels_hdbscan else 0)\n","noise_hdbscan = list(labels_hdbscan).count(-1)\n","\n","elapsed = time.time() - start\n","print(f\"      Found {n_clusters_hdbscan} clusters in {elapsed:.1f}s\")\n","print(f\"      Noise: {noise_hdbscan} ({noise_hdbscan/len(labels_hdbscan)*100:.1f}%)\")\n","clustering_results['HDBSCAN'] = labels_hdbscan\n","\n","# --------------------------------------------------\n","# Algorithm 2: BIRCH (OPTIMIZED)\n","# --------------------------------------------------\n","print(\"\\n   [Algorithm 2/4] BIRCH (optimized)...\")\n","start = time.time()\n","\n","# Try multiple thresholds and pick best\n","best_threshold = None\n","best_silhouette = -1\n","\n","for threshold in [0.3, 0.5, 0.7]:\n","    birch = Birch(threshold=threshold, n_clusters=n_true_categories)\n","    test_labels = birch.fit_predict(embeddings[:5000])  # Test on sample\n","\n","    from sklearn.metrics import silhouette_score\n","    try:\n","        score = silhouette_score(embeddings[:5000], test_labels, sample_size=1000)\n","        if score > best_silhouette:\n","            best_silhouette = score\n","            best_threshold = threshold\n","    except:\n","        pass\n","\n","print(f\"      Best threshold: {best_threshold}\")\n","\n","birch_clusterer = Birch(threshold=best_threshold, n_clusters=n_true_categories)\n","labels_birch = birch_clusterer.fit_predict(embeddings)\n","n_clusters_birch = len(set(labels_birch))\n","\n","elapsed = time.time() - start\n","print(f\"      Found {n_clusters_birch} clusters in {elapsed:.1f}s\")\n","clustering_results['BIRCH'] = labels_birch\n","\n","# --------------------------------------------------\n","# Algorithm 3: DBSCAN (MUCH BETTER EPSILON)\n","# --------------------------------------------------\n","print(\"\\n   [Algorithm 3/4] DBSCAN (improved epsilon)...\")\n","start = time.time()\n","\n","# Better epsilon estimation using elbow method\n","from sklearn.neighbors import NearestNeighbors\n","\n","sample_size = min(10000, len(embeddings))\n","rng = np.random.RandomState(RANDOM_SEED)\n","sample_idx = rng.choice(len(embeddings), sample_size, replace=False)\n","embeddings_sample = embeddings[sample_idx]\n","\n","k = 4\n","nbrs = NearestNeighbors(n_neighbors=k, n_jobs=-1).fit(embeddings_sample)\n","distances, indices = nbrs.kneighbors(embeddings_sample)\n","\n","# Sort distances\n","distances = np.sort(distances[:, k-1], axis=0)\n","\n","# Find elbow point (optimal epsilon)\n","# Use a much lower percentile for denser clusters\n","optimal_eps = np.percentile(distances, 70)  # Changed from 90 to 70\n","\n","print(f\"      Estimated optimal epsilon: {optimal_eps:.3f}\")\n","\n","# Try a few epsilon values around the estimate\n","best_eps = optimal_eps\n","best_n_clusters = 0\n","\n","for eps_multiplier in [0.7, 0.85, 1.0, 1.15, 1.3]:\n","    test_eps = optimal_eps * eps_multiplier\n","    dbscan_test = DBSCAN(eps=test_eps, min_samples=4, n_jobs=-1)\n","    test_labels = dbscan_test.fit_predict(embeddings_sample)\n","    test_n_clusters = len(set(test_labels)) - (1 if -1 in test_labels else 0)\n","\n","    # Prefer clusters closer to true count\n","    if abs(test_n_clusters - n_true_categories) < abs(best_n_clusters - n_true_categories):\n","        best_n_clusters = test_n_clusters\n","        best_eps = test_eps\n","\n","print(f\"      Using epsilon: {best_eps:.3f} (expecting ~{best_n_clusters} clusters)\")\n","\n","dbscan = DBSCAN(eps=best_eps, min_samples=4, n_jobs=-1)\n","labels_dbscan = dbscan.fit_predict(embeddings)\n","n_clusters_dbscan = len(set(labels_dbscan)) - (1 if -1 in labels_dbscan else 0)\n","\n","elapsed = time.time() - start\n","print(f\"      Found {n_clusters_dbscan} clusters in {elapsed:.1f}s\")\n","clustering_results['DBSCAN'] = labels_dbscan\n","\n","# --------------------------------------------------\n","# Algorithm 4: Agglomerative (OPTIMIZED)\n","# --------------------------------------------------\n","print(\"\\n   [Algorithm 4/4] Agglomerative (optimized)...\")\n","start = time.time()\n","\n","# Use cosine affinity for text embeddings\n","agg_clusterer = AgglomerativeClustering(\n","    n_clusters=n_true_categories,\n","    metric='cosine',  # Better for embeddings than euclidean\n","    linkage='average'  # More robust than ward for cosine\n",")\n","labels_agg = agg_clusterer.fit_predict(embeddings)\n","n_clusters_agg = len(set(labels_agg))\n","\n","elapsed = time.time() - start\n","print(f\"      Created {n_clusters_agg} clusters in {elapsed:.1f}s\")\n","clustering_results['Agglomerative'] = labels_agg\n","\n","print(\"\\n‚úÖ All clustering algorithms complete!\")\n","\n","# =============================================================================\n","# PART 7: EVALUATION (corrections_3.txt methodology)\n","# =============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"EVALUATION - 2-STEP VALIDATION\")\n","print(\"=\"*80)\n","\n","print(\"\\n[9/10] Evaluating clustering quality...\")\n","\n","def calculate_purity(predicted_labels, true_labels):\n","    \"\"\"STEP 2 from corrections_3.txt: Calculate purity\"\"\"\n","    mask = predicted_labels != -1\n","    predicted_filtered = predicted_labels[mask]\n","    true_filtered = true_labels[mask]\n","\n","    if len(predicted_filtered) == 0:\n","        return 0.0, 0\n","\n","    total_correct = 0\n","    for cluster_id in set(predicted_filtered):\n","        cluster_mask = predicted_filtered == cluster_id\n","        cluster_true_labels = true_filtered[cluster_mask]\n","        most_common_count = Counter(cluster_true_labels).most_common(1)[0][1]\n","        total_correct += most_common_count\n","\n","    purity = total_correct / len(predicted_filtered)\n","    noise = len(predicted_labels) - len(predicted_filtered)\n","\n","    return purity, noise\n","\n","def calculate_accuracy(predicted_labels, true_labels):\n","    \"\"\"STEP 3 from corrections_3.txt: Accuracy metric\"\"\"\n","    mask = predicted_labels != -1\n","    predicted_filtered = predicted_labels[mask]\n","    true_filtered = true_labels[mask]\n","\n","    if len(predicted_filtered) == 0:\n","        return 0.0\n","\n","    cluster_dominant_category = {}\n","    for cluster_id in set(predicted_filtered):\n","        cluster_mask = predicted_filtered == cluster_id\n","        cluster_true_labels = true_filtered[cluster_mask]\n","        dominant_cat = Counter(cluster_true_labels).most_common(1)[0][0]\n","        cluster_dominant_category[cluster_id] = dominant_cat\n","\n","    correctly_placed = sum(\n","        1 for pred_cluster, true_cat in zip(predicted_filtered, true_filtered)\n","        if cluster_dominant_category[pred_cluster] == true_cat\n","    )\n","\n","    return correctly_placed / len(predicted_labels)\n","\n","# Evaluate all algorithms\n","evaluation_results = {}\n","\n","for algo_name, predicted_labels in clustering_results.items():\n","    print(f\"\\n{'='*80}\")\n","    print(f\"{algo_name}\")\n","    print(f\"{'='*80}\")\n","\n","    # STEP 1: Cluster count match\n","    n_predicted = len(set(predicted_labels)) - (1 if -1 in predicted_labels else 0)\n","    print(f\"   Predicted clusters: {n_predicted}\")\n","    print(f\"   True categories: {n_true_categories}\")\n","    print(f\"   Difference: {abs(n_predicted - n_true_categories)}\")\n","\n","    # STEP 2: Purity\n","    purity, noise = calculate_purity(predicted_labels, true_labels)\n","    print(f\"\\n   Purity: {purity:.2%}\")\n","    print(f\"   Noise points: {noise} ({noise/len(predicted_labels)*100:.1f}%)\")\n","\n","    # STEP 3: Accuracy\n","    accuracy = calculate_accuracy(predicted_labels, true_labels)\n","    print(f\"   Accuracy: {accuracy:.2%}\")\n","\n","    # Additional metrics\n","    nmi = normalized_mutual_info_score(true_labels, predicted_labels)\n","    ari = adjusted_rand_score(true_labels, predicted_labels)\n","    print(f\"   NMI: {nmi:.2%}\")\n","    print(f\"   ARI: {ari:.2%}\")\n","\n","    # Pass/Fail\n","    passes_target = (accuracy >= TARGET_ACCURACY and purity >= TARGET_PURITY)\n","    print(f\"\\n   Target Met: {'‚úÖ YES' if passes_target else '‚ùå NO'}\")\n","\n","    evaluation_results[algo_name] = {\n","        'n_clusters': n_predicted,\n","        'purity': purity,\n","        'accuracy': accuracy,\n","        'nmi': nmi,\n","        'ari': ari,\n","        'noise': noise,\n","        'passes_target': passes_target\n","    }\n","\n","print(\"\\n‚úÖ Evaluation complete!\")\n","\n","# =============================================================================\n","# PART 8: RESULTS SUMMARY\n","# =============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"RESULTS SUMMARY\")\n","print(\"=\"*80)\n","\n","summary_df = pd.DataFrame({\n","    algo: {\n","        'Accuracy': f\"{metrics['accuracy']:.2%}\",\n","        'Purity': f\"{metrics['purity']:.2%}\",\n","        'NMI': f\"{metrics['nmi']:.2%}\",\n","        'N_Clusters': metrics['n_clusters'],\n","        'Target_Met': '‚úÖ' if metrics['passes_target'] else '‚ùå'\n","    }\n","    for algo, metrics in evaluation_results.items()\n","}).T\n","\n","print(\"\\n\", summary_df)\n","\n","# Find best algorithm\n","best_algo = max(evaluation_results.items(), key=lambda x: x[1]['accuracy'])\n","best_name, best_metrics = best_algo\n","\n","print(f\"\\n{'='*80}\")\n","print(f\"üèÜ BEST ALGORITHM: {best_name}\")\n","print(f\"{'='*80}\")\n","print(f\"   Accuracy: {best_metrics['accuracy']:.2%}\")\n","print(f\"   Purity: {best_metrics['purity']:.2%}\")\n","print(f\"   NMI: {best_metrics['nmi']:.2%}\")\n","print(f\"   Clusters: {best_metrics['n_clusters']} (true: {n_true_categories})\")\n","print(f\"\\n   Target Achieved: {'‚úÖ YES!' if best_metrics['passes_target'] else '‚ùå Not yet'}\")\n","print(f\"{'='*80}\")\n","\n","# =============================================================================\n","# PART 9: VISUALIZATIONS\n","# =============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"GENERATING VISUALIZATIONS\")\n","print(\"=\"*80)\n","\n","print(\"\\n[10/10] Creating plots...\")\n","\n","# Set style\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.dpi'] = 100\n","\n","# 1. Category Distribution\n","print(\"\\n   [Plot 1/5] Category distribution...\")\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n","\n","counts = df['level3'].value_counts()\n","counts.head(30).plot(kind='barh', ax=ax1)\n","ax1.set_title('Top 30 Categories', fontsize=14, fontweight='bold')\n","ax1.set_xlabel('Number of Products')\n","ax1.invert_yaxis()\n","\n","ax2.hist(counts.values, bins=50, edgecolor='black')\n","ax2.set_title('Distribution of Products per Category', fontsize=14, fontweight='bold')\n","ax2.set_xlabel('Number of Products')\n","ax2.set_ylabel('Number of Categories')\n","ax2.axvline(counts.median(), color='red', linestyle='--', label=f'Median: {counts.median():.0f}')\n","ax2.legend()\n","\n","plt.tight_layout()\n","plt.savefig(f'{OUTPUT_DIR}/01_category_distribution.png', bbox_inches='tight', dpi=300)\n","plt.show()\n","print(f\"      Saved: {OUTPUT_DIR}/01_category_distribution.png\")\n","\n","# 2. UMAP 2D Projection (sample for speed)\n","print(\"\\n   [Plot 2/5] UMAP 2D projection (this may take a few minutes)...\")\n","sample_size = min(VIZ_SAMPLE_SIZE, len(embeddings))\n","np.random.seed(RANDOM_SEED)\n","idx = np.random.choice(len(embeddings), sample_size, replace=False)\n","\n","reducer = umap.UMAP(n_components=2, random_state=RANDOM_SEED)\n","embeddings_2d = reducer.fit_transform(embeddings[idx])\n","\n","fig, ax = plt.subplots(figsize=(12, 8))\n","scatter = ax.scatter(\n","    embeddings_2d[:, 0],\n","    embeddings_2d[:, 1],\n","    c=pd.factorize(df['level3'].iloc[idx])[0],\n","    cmap='tab20',\n","    alpha=0.6,\n","    s=10\n",")\n","ax.set_title('UMAP Projection (Colored by True Categories)', fontsize=14, fontweight='bold')\n","ax.set_xlabel('UMAP Dimension 1')\n","ax.set_ylabel('UMAP Dimension 2')\n","plt.tight_layout()\n","plt.savefig(f'{OUTPUT_DIR}/02_embeddings_umap.png', bbox_inches='tight', dpi=300)\n","plt.show()\n","print(f\"      Saved: {OUTPUT_DIR}/02_embeddings_umap.png\")\n","\n","# 3. Best Algorithm Clusters\n","print(f\"\\n   [Plot 3/5] {best_name} cluster visualization...\")\n","fig, ax = plt.subplots(figsize=(12, 8))\n","scatter = ax.scatter(\n","    embeddings_2d[:, 0],\n","    embeddings_2d[:, 1],\n","    c=clustering_results[best_name][idx],\n","    cmap='tab20',\n","    alpha=0.6,\n","    s=10\n",")\n","ax.set_title(f'{best_name} Clustering Results', fontsize=14, fontweight='bold')\n","ax.set_xlabel('UMAP Dimension 1')\n","ax.set_ylabel('UMAP Dimension 2')\n","plt.tight_layout()\n","plt.savefig(f'{OUTPUT_DIR}/03_{best_name}_clusters.png', bbox_inches='tight', dpi=300)\n","plt.show()\n","print(f\"      Saved: {OUTPUT_DIR}/03_{best_name}_clusters.png\")\n","\n","# 4. Algorithm Comparison\n","print(\"\\n   [Plot 4/5] Algorithm comparison...\")\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","\n","metrics_to_plot = ['accuracy', 'purity', 'nmi']\n","for i, metric in enumerate(metrics_to_plot):\n","    data = [evaluation_results[algo][metric] for algo in evaluation_results]\n","    axes[i].bar(evaluation_results.keys(), data, color='steelblue')\n","    axes[i].set_title(f'{metric.upper()}', fontsize=12, fontweight='bold')\n","    axes[i].set_ylabel('Score')\n","    axes[i].set_ylim(0, 1)\n","    axes[i].axhline(TARGET_ACCURACY if metric == 'accuracy' else TARGET_PURITY if metric == 'purity' else 0.8,\n","                   color='red', linestyle='--', label='Target')\n","    axes[i].legend()\n","    axes[i].tick_params(axis='x', rotation=45)\n","\n","plt.suptitle('Clustering Algorithm Comparison', fontsize=16, fontweight='bold')\n","plt.tight_layout()\n","plt.savefig(f'{OUTPUT_DIR}/04_algorithm_comparison.png', bbox_inches='tight', dpi=300)\n","plt.show()\n","print(f\"      Saved: {OUTPUT_DIR}/04_algorithm_comparison.png\")\n","\n","# 5. Results Table\n","print(\"\\n   [Plot 5/5] Results table...\")\n","fig, ax = plt.subplots(figsize=(12, 6))\n","ax.axis('tight')\n","ax.axis('off')\n","\n","table_data = []\n","for algo, metrics in evaluation_results.items():\n","    table_data.append([\n","        algo,\n","        f\"{metrics['accuracy']:.1%}\",\n","        f\"{metrics['purity']:.1%}\",\n","        f\"{metrics['nmi']:.1%}\",\n","        f\"{metrics['n_clusters']}\",\n","        '‚úÖ' if metrics['passes_target'] else '‚ùå'\n","    ])\n","\n","table = ax.table(\n","    cellText=table_data,\n","    colLabels=['Algorithm', 'Accuracy', 'Purity', 'NMI', 'Clusters', 'Target'],\n","    cellLoc='center',    loc='center',\n","    colWidths=[0.2, 0.15, 0.15, 0.15, 0.15, 0.1]\n",")\n","\n","table.auto_set_font_size(False)\n","table.set_fontsize(10)\n","table.scale(1, 2)\n","\n","# Color header\n","for i in range(6):\n","    table[(0, i)].set_facecolor('#4472C4')\n","    table[(0, i)].set_text_props(weight='bold', color='white')\n","\n","# Color target column\n","for i in range(1, len(table_data) + 1):\n","    if table_data[i-1][5] == '‚úÖ':\n","        table[(i, 5)].set_facecolor('#C6EFCE')\n","    else:\n","        table[(i, 5)].set_facecolor('#FFC7CE')\n","\n","plt.title('Final Results Summary', fontsize=14, fontweight='bold', pad=20)\n","plt.savefig(f'{OUTPUT_DIR}/05_results_summary.png', bbox_inches='tight', dpi=300)\n","plt.show()\n","print(f\"      Saved: {OUTPUT_DIR}/05_results_summary.png\")\n","\n","print(\"\\n‚úÖ All visualizations created!\")\n","\n","# =============================================================================\n","# PART 10: SAVE RESULTS\n","# =============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"SAVING RESULTS\")\n","print(\"=\"*80)\n","\n","# Save summary CSV\n","summary_df.to_csv(f\"{OUTPUT_DIR}/clustering_results_summary.csv\")\n","print(f\"‚úÖ Saved: {OUTPUT_DIR}/clustering_results_summary.csv\")\n","\n","# Save predictions\n","df['predicted_cluster'] = clustering_results[best_name]\n","df[['Brand', 'level3', 'predicted_cluster', 'combined_text']].to_csv(\n","    f\"{OUTPUT_DIR}/predictions.csv\",\n","    index=False\n",")\n","print(f\"‚úÖ Saved: {OUTPUT_DIR}/predictions.csv\")\n","\n","# =============================================================================\n","# FINAL MESSAGE\n","# =============================================================================\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úÖ PIPELINE COMPLETE!\")\n","print(\"=\"*80)\n","print(f\"\\nüèÜ Best Algorithm: {best_name}\")\n","print(f\"   Accuracy: {best_metrics['accuracy']:.2%}\")\n","print(f\"   Purity: {best_metrics['purity']:.2%}\")\n","print(f\"   Target Achieved: {'YES! üéâ' if best_metrics['passes_target'] else 'Not yet - try tuning parameters'}\")\n","print(f\"\\nüìÅ All results saved to: {OUTPUT_DIR}/\")\n","print(f\"\\n{'='*80}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tioZTmNmDJTz","outputId":"dca412ad-f1ae-4f7b-8629-cb2bce93b887"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","CLUSTERING ALGORITHMS (OPTIMIZED FOR ACCURACY)\n","================================================================================\n","   True categories: 114\n","   Total products: 32,885\n","\n","   [Algorithm 1/4] HDBSCAN (optimized)...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PrttAyrESBG2"},"execution_count":null,"outputs":[]}]}